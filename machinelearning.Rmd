
---
title: "Identifying Correct Dumbell Lifts"
author: "Liesl Schwab"
date: "Tuesday, July 14, 2015"
output: html_document
---

## Introduction
Our goal for this project is to examine data collected from a small subset of six men aged 20-28 and try to determine how they were lifting the dumbbell given the measurements taken during the lifting. This type of activity identification could be very useful in a variety of applications; for example, providing feedback to athletes.

## Processing Data

####Load required libraries:
```{r, echo = FALSE }
setwd( "C:/Users/lschwab/Documents/Coursera Data Science/PracMachineLearning Project" )
```

```{r}
library( caret )
library( rpart )
library( rattle )
library( rpart.plot )
library( AppliedPredictiveModeling )
library( randomForest )
set.seed( 125 ) ## Set the seed for reproduction
```

####Load the required datasets:
Let NA's, DIV/0!, and blank entries all be considered NA values. Let us also clean the data to eliminate variables that may not be of as much use during prediction of the type of activity. First, we remove the first 7 columns as they are not useful predictors, then we remove columns that contain a majority of NA values (over 60%) as they are also not useful predictors.
```{r}
bigtrain <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))

## Remove first 7 cols
bigtrain <- bigtrain[,8:length(colnames(bigtrain))]

## Remove close to zero variance cols and cols with large number of NAs
drop <- c()
for( col in 1:(ncol( bigtrain ) - 1) ){
      colname <- colnames(bigtrain)[col]
      if( sum( is.na( bigtrain[,col])) / nrow( bigtrain ) >= 0.6  ) drop <- c( drop, colnames(bigtrain)[col])
}

bigtrain <- bigtrain[,!colnames(bigtrain) %in% drop]
```
Our remaining predictors are then:
```{r}
colnames( bigtrain )
```
Then, let us split the given training data into a training set and a test set:
```{r}
# Split the training set into a training and test set
inTrain <- createDataPartition( y = bigtrain$classe, p = 0.6, list = FALSE )
newtrain <- bigtrain[ inTrain, ]
newtest <- bigtrain[ -inTrain, ]
```

## Predictions

### Classification Tree
First, we will run a prediction using a decision/classification tree:
```{r}
fit1 <- rpart( classe ~ ., data = newtrain, method = "class" )
pred1 <- predict( fit1, newdata = newtest, type = "class" )

## View Plot
rpart.plot(fit1)
```

Then we will examine the confusion matrix:
```{r}
cm1 <- confusionMatrix( pred1, newtest$classe )
cm1
```
The accuracy is good, but perhaps a different method could provide better results.

### Random Forest
Next, we will run a prediction using a random forest:
```{r}
fit2 <- randomForest( classe ~ ., data = newtrain )
pred2 <- predict( fit2, newdata = newtest, type = "class" )
```

Then we will examine the confusion matrix:
```{r}
cm2 <- confusionMatrix( pred2, newtest$classe )
cm2
```
From this confusion matrix we can see that the random forest analysis give a much better accuracy than the classification tree we generated earlier.

### Out of Sample Error
We will quickly examine the out of sample error for the two methods that we applied. The out of sample error is 1 - accuracy, so for the classification tree we have:
```{r}
1 - cm1$overall['Accuracy']
```

and for the random forest method we have:
```{r}
1 - cm2$overall['Accuracy']
```

## Apply Model Fits to the Test Sample
The last step in testing out our models is to apply them to the test set of 20 samples. First, for the classification tree we have:
```{r}
pred3 <- predict( fit1, newdata = test, type = "class" )
print( pred3 )
```

And for the random forest we have:
```{r}
pred4 <- predict( fit2, newdata = test, type = "class" )
print( pred4 )
```

## Conclusion

Of the two models that we predicted with, the random forest model gave a higher accuracy and a lower out of smaple error, so I choose to submit the prediction of the test set generated by our random forest model. Since the out of sample error of the random forest model was so low, all of the 20 predictions were predicted correctly. As such, we can conclude that the random forest model for this set of predictions is a good way to predict the type of motion being performed.